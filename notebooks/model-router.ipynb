{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eb9bec9-49c9-4dae-8d6b-e8205ee03a7a",
   "metadata": {},
   "source": [
    "# Model Router\n",
    "\n",
    "**Model router** for Azure AI Foundry is a deployable AI chat model that is trained to select the best large language model (LLM) to respond to a given prompt in real time. By evaluating factors like query complexity, cost, and performance, it intelligently routes requests to the most suitable model. Thus, it delivers high performance while saving on compute costs where possible, all packaged as a single model deployment.\n",
    "\n",
    "**Model router intelligently selects the best underlying model for a given prompt to optimize costs** while maintaining quality. Smaller and cheaper models are used when they're sufficient for the task, but larger and more expensive models are available for more complex tasks. Also, reasoning models are available for tasks that require complex reasoning, and non-reasoning models are used otherwise. Model router provides a single deployment and chat experience that combines the best features from all of the underlying chat models.\n",
    "\n",
    "Model router will use these models:\n",
    "- 2025-05-19\tGPT-4.1 (2025-04-14)\n",
    "- GPT-4.1-mini (2025-04-14)\n",
    "- GPT-4.1-nano (2025-04-14)\n",
    "- o4-mini (2025-04-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4feff79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install azure-identity\n",
    "#%pip install python-dotenv openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2af7ddc-f942-4e13-a973-6485e3975170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "881b60c5-0ccf-4fa5-9586-aebcd5487377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Azure OpenAI endpoint: https://aq-ai-foundry-sweden-central.cognitiveservices.azure.com/\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "endpoint = os.getenv(\"azure_openai_endpoint\")\n",
    "model = \"model-router-2\"\n",
    "\n",
    "print(f\"Using Azure OpenAI endpoint: {endpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "965683bb-aaa8-4f26-951f-2104f7c27b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure OpenAI client with Entra ID authentication\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    azure_ad_token_provider=token_provider,\n",
    "    api_version=\"2025-01-01-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46272cd7-3aaf-44c7-ba00-d0ba902c6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelrouter(prompt):\n",
    "    \"\"\"\n",
    "    Generates a response from the chat model based on the provided prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The user's input to which the chat model will respond.\n",
    "\n",
    "    Returns:\n",
    "        response: The complete response object from the chat model, including the generated message and model details.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        print()\n",
    "        print(\"\\033[1;31;34m\")\n",
    "        print(response.choices[0].message.content)\n",
    "        print(\"\\033[1;31;32m\")\n",
    "        print()\n",
    "        print(f\"This model was automatically selected: {response.model}\")\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5587f174-2f66-4b19-a15f-4417b17bcea8",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6154725-1804-4907-b3b7-b9773467ac57",
   "metadata": {},
   "source": [
    "### Basic prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d87595c-9c24-4f38-bf58-68620b0208d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31;34m\n",
      "FIFA (Fédération Internationale de Football Association) is the international governing body for association football (soccer), as well as futsal and beach soccer. Key points:\n",
      "\n",
      "- Founded in 1904 and headquartered in Zurich, Switzerland.\n",
      "- Membership: 211 national football associations (more than the United Nations).\n",
      "- Main roles:\n",
      "  - Organizes major international competitions, most notably the men’s FIFA World Cup (first held in 1930) and the FIFA Women’s World Cup, plus youth, futsal and beach-soccer world championships and the FIFA Club World Cup.\n",
      "  - Oversees international match calendars and tournament rules at the global level.\n",
      "  - Distributes development funding, coaching and referee education, and other support to member associations.\n",
      "  - Works with regional confederations (e.g., UEFA, CONMEBOL, CONCACAF, CAF, AFC, OFC) to run continental competitions and development programs.\n",
      "- Relationship to the Laws of the Game: The Laws are maintained by the International Football Association Board (IFAB); FIFA is one of IFAB’s members and implements those laws in competitions.\n",
      "- Governance: Led by an elected President and a FIFA Council (previously the FIFA Executive Committee). FIFA has faced notable governance controversies and corruption scandals, which prompted reforms in recent years.\n",
      "- Economic impact: FIFA is a major commercial organization, financing operations and development programs primarily through World Cup-related broadcasting and sponsorship revenue.\n",
      "\n",
      "In short, FIFA is the global organization that administers and promotes international football, organizes the World Cup tournaments, and coordinates the sport among national associations.\n",
      "\u001b[1;31;32m\n",
      "\n",
      "This model was automatically selected: gpt-5-mini-2025-08-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C3PZ3zVo2EjULpDupocuMEKhjVbdo', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='FIFA (Fédération Internationale de Football Association) is the international governing body for association football (soccer), as well as futsal and beach soccer. Key points:\\n\\n- Founded in 1904 and headquartered in Zurich, Switzerland.\\n- Membership: 211 national football associations (more than the United Nations).\\n- Main roles:\\n  - Organizes major international competitions, most notably the men’s FIFA World Cup (first held in 1930) and the FIFA Women’s World Cup, plus youth, futsal and beach-soccer world championships and the FIFA Club World Cup.\\n  - Oversees international match calendars and tournament rules at the global level.\\n  - Distributes development funding, coaching and referee education, and other support to member associations.\\n  - Works with regional confederations (e.g., UEFA, CONMEBOL, CONCACAF, CAF, AFC, OFC) to run continental competitions and development programs.\\n- Relationship to the Laws of the Game: The Laws are maintained by the International Football Association Board (IFAB); FIFA is one of IFAB’s members and implements those laws in competitions.\\n- Governance: Led by an elected President and a FIFA Council (previously the FIFA Executive Committee). FIFA has faced notable governance controversies and corruption scandals, which prompted reforms in recent years.\\n- Economic impact: FIFA is a major commercial organization, financing operations and development programs primarily through World Cup-related broadcasting and sponsorship revenue.\\n\\nIn short, FIFA is the global organization that administers and promotes international football, organizes the World Cup tournaments, and coordinates the sport among national associations.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1754929289, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=458, prompt_tokens=20, total_tokens=478, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=128, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What is FIFA?\"\n",
    "\n",
    "modelrouter(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276801a-0a3c-4bb0-90d6-bc588024bd4e",
   "metadata": {},
   "source": [
    "### Medium complex prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498043b4-b76f-492a-a6ec-6501d10919d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31;34m\n",
      "The most recent FIFA World Cup was held in 2022, and Argentina won the tournament. Argentina defeated France in the final, securing their third World Cup title.\n",
      "\n",
      "### Financial Aspects for Argentina:\n",
      "\n",
      "1. **Prize Money:**\n",
      "   - Argentina, as the champion of the 2022 World Cup, received a significant prize money reward from FIFA. The total prize money for the winner was approximately $42 million.\n",
      "   - This prize money is distributed among the national football association, players, coaching staff, and other stakeholders.\n",
      "\n",
      "2. **Economic Impact:**\n",
      "   - Winning the World Cup often boosts a country's football economy. For Argentina, the victory increased interest in football domestically, leading to higher merchandise sales, increased sponsorship deals, and greater investment in football infrastructure.\n",
      "   - The success also enhances the marketability of Argentine players internationally, potentially increasing their transfer values and salaries.\n",
      "\n",
      "3. **Sponsorship and Endorsements:**\n",
      "   - The win elevated the global profile of key Argentine players like Lionel Messi, leading to lucrative endorsement deals and sponsorships.\n",
      "   - National brands and international companies often leverage such victories to launch marketing campaigns, which can increase advertising revenues for Argentine media.\n",
      "\n",
      "4. **Tourism and National Pride:**\n",
      "   - Although not directly financial, the World Cup victory boosts national pride and can stimulate tourism as fans and tourists are drawn to celebrate and explore the country.\n",
      "   - This increased tourism can indirectly contribute to the economy through spending on hospitality, travel, and entertainment.\n",
      "\n",
      "5. **Long-term Investments:**\n",
      "   - The Argentine Football Association (AFA) may receive increased funding and government support for youth development programs, stadium improvements, and grassroots football initiatives following the World Cup success.\n",
      "   - This can contribute to sustainable growth in the sport, potentially leading to future financial gains.\n",
      "\n",
      "### Summary:\n",
      "Argentina's 2022 World Cup victory brought immediate financial rewards through prize money and boosted the football economy via increased sponsorships, merchandise sales, and global recognition. The win also has positive ripple effects on tourism and long-term investments in the sport within the country.\n",
      "\u001b[1;31;32m\n",
      "\n",
      "This model was automatically selected: gpt-4.1-mini-2025-04-14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C3PZ8pbmBFmMNm7JoVVjUjCHhe1K1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The most recent FIFA World Cup was held in 2022, and Argentina won the tournament. Argentina defeated France in the final, securing their third World Cup title.\\n\\n### Financial Aspects for Argentina:\\n\\n1. **Prize Money:**\\n   - Argentina, as the champion of the 2022 World Cup, received a significant prize money reward from FIFA. The total prize money for the winner was approximately $42 million.\\n   - This prize money is distributed among the national football association, players, coaching staff, and other stakeholders.\\n\\n2. **Economic Impact:**\\n   - Winning the World Cup often boosts a country's football economy. For Argentina, the victory increased interest in football domestically, leading to higher merchandise sales, increased sponsorship deals, and greater investment in football infrastructure.\\n   - The success also enhances the marketability of Argentine players internationally, potentially increasing their transfer values and salaries.\\n\\n3. **Sponsorship and Endorsements:**\\n   - The win elevated the global profile of key Argentine players like Lionel Messi, leading to lucrative endorsement deals and sponsorships.\\n   - National brands and international companies often leverage such victories to launch marketing campaigns, which can increase advertising revenues for Argentine media.\\n\\n4. **Tourism and National Pride:**\\n   - Although not directly financial, the World Cup victory boosts national pride and can stimulate tourism as fans and tourists are drawn to celebrate and explore the country.\\n   - This increased tourism can indirectly contribute to the economy through spending on hospitality, travel, and entertainment.\\n\\n5. **Long-term Investments:**\\n   - The Argentine Football Association (AFA) may receive increased funding and government support for youth development programs, stadium improvements, and grassroots football initiatives following the World Cup success.\\n   - This can contribute to sustainable growth in the sport, potentially leading to future financial gains.\\n\\n### Summary:\\nArgentina's 2022 World Cup victory brought immediate financial rewards through prize money and boosted the football economy via increased sponsorships, merchandise sales, and global recognition. The win also has positive ripple effects on tourism and long-term investments in the sport within the country.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'detected': False, 'filtered': False}, 'protected_material_text': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1754929294, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier=None, system_fingerprint='fp_4f3d32ad4e', usage=CompletionUsage(completion_tokens=419, prompt_tokens=37, total_tokens=456, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Who  won the last world cup? Explain the details for the country in terms of financial aspects.\"\n",
    "\n",
    "modelrouter(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271eda66-6c36-48b4-9cfb-a2272797edbb",
   "metadata": {},
   "source": [
    "### Reasoning prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e16eca21-cb5e-4e1d-b736-27c636539107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31;34m\n",
      "The 2022 FIFA World Cup was won by **Argentina**.\n",
      "\n",
      "### Different Perspectives on Argentina’s Victory:\n",
      "\n",
      "- **From Argentina’s Perspective:**\n",
      "  The victory was monumental, marking their third World Cup title and their first since 1986. It was a crowning achievement for Lionel Messi, often regarded as one of the greatest footballers of all time, who finally lifted the trophy that had eluded him. The win sparked massive celebrations across Argentina, symbolizing national pride and unity.\n",
      "\n",
      "- **Global Football Community:**\n",
      "  Argentina’s triumph was widely celebrated and viewed as a testament to the enduring legacy of traditional footballing powerhouses. It also reinforced the narrative of Messi’s illustrious career. For many fans worldwide, it was an emotional and dramatic tournament, culminating in a thrilling final that showcased the beauty and unpredictability of football.\n",
      "\n",
      "- **For Competing Teams:**\n",
      "  Teams such as France, the runners-up, and other strong contenders like Brazil and Germany, viewed Argentina’s win as a reminder of the importance of experience, leadership, and tactical discipline in high-stakes tournaments.\n",
      "\n",
      "### Impact on Global Football:\n",
      "\n",
      "- **Revival of South American Football:**\n",
      "  Argentina’s win helped highlight the strength of South American football on the global stage, emphasizing technical skill, creativity, and passion.\n",
      "\n",
      "- **Inspiration for Future Generations:**\n",
      "  Messi’s success story and the team’s resilience inspired young players worldwide, encouraging them to develop their craft and aspire to the highest levels.\n",
      "\n",
      "- **Tactical Evolution:**\n",
      "  The tournament underlined the effectiveness of flexible tactics that balance possession, quick transitions, and solid defensive work, influencing coaching philosophies globally.\n",
      "\n",
      "### Tactical Approach in Key Matches:\n",
      "\n",
      "- **Group Stage and Knockouts:**\n",
      "  Argentina started the tournament with some struggles but found their rhythm as it progressed. Their approach combined a strong defensive structure with creative attacking play, primarily orchestrated by Messi.\n",
      "\n",
      "- **Use of Messi as a False Nine:**\n",
      "  In many matches, Messi operated in a free role, dropping deep to link midfield and attack, creating space for forwards like Lautaro Martínez and Ángel Di María.\n",
      "\n",
      "- **Midfield Control:**\n",
      "  The midfield, led by players like Rodrigo De Paul and Enzo Fernández, was crucial in controlling the tempo, breaking up opposition plays, and providing service to the forwards.\n",
      "\n",
      "- **Adaptability:**\n",
      "  Coach Lionel Scaloni demonstrated tactical flexibility, adjusting formations and strategies depending on the opponent. For example, in the final against France, Argentina started with a 4-3-3 formation focusing on controlling the midfield and exploiting wide areas.\n",
      "\n",
      "- **Mental Resilience:**\n",
      "  Argentina showed tremendous mental strength, overcoming early setbacks (such as their opening loss to Saudi Arabia) and handling pressure in penalty shootouts (notably in the quarterfinal against the Netherlands).\n",
      "\n",
      "### Conclusion:\n",
      "\n",
      "Argentina’s 2022 FIFA World Cup victory was a historic and emotional moment for football. It highlighted the importance of experienced leadership, tactical adaptability, and individual brilliance. The win resonated globally, inspiring fans and players alike, and reaffirmed Argentina’s place among football’s elite nations.\n",
      "\u001b[1;31;32m\n",
      "\n",
      "This model was automatically selected: gpt-4.1-mini-2025-04-14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C3PZE3S4usVYG9GIA1thPycZWDyWJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The 2022 FIFA World Cup was won by **Argentina**.\\n\\n### Different Perspectives on Argentina’s Victory:\\n\\n- **From Argentina’s Perspective:**\\n  The victory was monumental, marking their third World Cup title and their first since 1986. It was a crowning achievement for Lionel Messi, often regarded as one of the greatest footballers of all time, who finally lifted the trophy that had eluded him. The win sparked massive celebrations across Argentina, symbolizing national pride and unity.\\n\\n- **Global Football Community:**\\n  Argentina’s triumph was widely celebrated and viewed as a testament to the enduring legacy of traditional footballing powerhouses. It also reinforced the narrative of Messi’s illustrious career. For many fans worldwide, it was an emotional and dramatic tournament, culminating in a thrilling final that showcased the beauty and unpredictability of football.\\n\\n- **For Competing Teams:**\\n  Teams such as France, the runners-up, and other strong contenders like Brazil and Germany, viewed Argentina’s win as a reminder of the importance of experience, leadership, and tactical discipline in high-stakes tournaments.\\n\\n### Impact on Global Football:\\n\\n- **Revival of South American Football:**\\n  Argentina’s win helped highlight the strength of South American football on the global stage, emphasizing technical skill, creativity, and passion.\\n\\n- **Inspiration for Future Generations:**\\n  Messi’s success story and the team’s resilience inspired young players worldwide, encouraging them to develop their craft and aspire to the highest levels.\\n\\n- **Tactical Evolution:**\\n  The tournament underlined the effectiveness of flexible tactics that balance possession, quick transitions, and solid defensive work, influencing coaching philosophies globally.\\n\\n### Tactical Approach in Key Matches:\\n\\n- **Group Stage and Knockouts:**\\n  Argentina started the tournament with some struggles but found their rhythm as it progressed. Their approach combined a strong defensive structure with creative attacking play, primarily orchestrated by Messi.\\n\\n- **Use of Messi as a False Nine:**\\n  In many matches, Messi operated in a free role, dropping deep to link midfield and attack, creating space for forwards like Lautaro Martínez and Ángel Di María.\\n\\n- **Midfield Control:**\\n  The midfield, led by players like Rodrigo De Paul and Enzo Fernández, was crucial in controlling the tempo, breaking up opposition plays, and providing service to the forwards.\\n\\n- **Adaptability:**\\n  Coach Lionel Scaloni demonstrated tactical flexibility, adjusting formations and strategies depending on the opponent. For example, in the final against France, Argentina started with a 4-3-3 formation focusing on controlling the midfield and exploiting wide areas.\\n\\n- **Mental Resilience:**\\n  Argentina showed tremendous mental strength, overcoming early setbacks (such as their opening loss to Saudi Arabia) and handling pressure in penalty shootouts (notably in the quarterfinal against the Netherlands).\\n\\n### Conclusion:\\n\\nArgentina’s 2022 FIFA World Cup victory was a historic and emotional moment for football. It highlighted the importance of experienced leadership, tactical adaptability, and individual brilliance. The win resonated globally, inspiring fans and players alike, and reaffirmed Argentina’s place among football’s elite nations.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'detected': False, 'filtered': False}, 'protected_material_text': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1754929300, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier=None, system_fingerprint='fp_4f3d32ad4e', usage=CompletionUsage(completion_tokens=630, prompt_tokens=53, total_tokens=683, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Who won the 2022 FIFA World Cup? Consider different perspectives, analyze the impact of the victory on global football, and discuss the team’s tactical approach in key matches.\n",
    "\"\"\"\n",
    "\n",
    "modelrouter(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "563f7893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31;34m\n",
      "Sure! Here’s your list converted into lowercase kebab-case and separated by commas:\n",
      "\n",
      "```\n",
      "wireless-headphones-pro, bluetooth-speaker-x3, smartwatch-series-7\n",
      "```\n",
      "\u001b[1;31;32m\n",
      "\n",
      "This model was automatically selected: gpt-5-chat-latest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C3PZOqHQvEQxdaixroqa1F4wL9iCf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Sure! Here’s your list converted into lowercase kebab-case and separated by commas:\\n\\n```\\nwireless-headphones-pro, bluetooth-speaker-x3, smartwatch-series-7\\n```', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1754929310, model='gpt-5-chat-latest', object='chat.completion', service_tier=None, system_fingerprint='fp_7560107781', usage=CompletionUsage(completion_tokens=38, prompt_tokens=48, total_tokens=86, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question for GPT-5 series models\n",
    "prompt = \"Convert this product title list into lowercase kebab-case (comma-separated): ‘Wireless Headphones Pro, Bluetooth Speaker X3, Smartwatch Series 7’.\"\n",
    "\n",
    "modelrouter(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a96c53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31;34m\n",
      "The first constitutional President of Mexico was Guadalupe Victoria (born José Miguel Ramón Adaucto Fernández y Félix). He served as President from October 10, 1824 to March 31, 1829.\n",
      "\n",
      "(If you mean the first head of an independent Mexico overall, Agustín de Iturbide ruled first as Emperor from 1822–1823, but he was not a president.)\n",
      "\u001b[1;31;32m\n",
      "\n",
      "This model was automatically selected: gpt-5-mini-2025-08-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C3PZP3g5iqIBGjO9HP9dgqBg8sKUf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The first constitutional President of Mexico was Guadalupe Victoria (born José Miguel Ramón Adaucto Fernández y Félix). He served as President from October 10, 1824 to March 31, 1829.\\n\\n(If you mean the first head of an independent Mexico overall, Agustín de Iturbide ruled first as Emperor from 1822–1823, but he was not a president.)', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1754929311, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=219, prompt_tokens=26, total_tokens=245, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=128, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EASY question to test the model router\n",
    "prompt = \"\"\"\n",
    "Who was the first President of Mexico?  \n",
    "\"\"\"\n",
    "modelrouter(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb75de53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31;34m\n",
      "Let's solve the optimization problem step-by-step:\n",
      "\n",
      "---\n",
      "\n",
      "**Problem:**\n",
      "\n",
      "Maximize \\( f(x,y) = 3x + 4y \\)\n",
      "\n",
      "subject to the constraints:\n",
      "\n",
      "\\[\n",
      "\\begin{cases}\n",
      "2x + 3y \\leq 12 \\\\\n",
      "x \\geq 0 \\\\\n",
      "y \\geq 0\n",
      "\\end{cases}\n",
      "\\]\n",
      "\n",
      "---\n",
      "\n",
      "### Step 1: Understand the problem\n",
      "\n",
      "We want to find values of \\(x\\) and \\(y\\) that maximize the linear function \\(f(x,y) = 3x + 4y\\), but these values must satisfy the constraints.\n",
      "\n",
      "The constraints form a feasible region in the first quadrant (since \\(x,y \\geq 0\\)) bounded by the line \\(2x + 3y = 12\\).\n",
      "\n",
      "---\n",
      "\n",
      "### Step 2: Identify the feasible region\n",
      "\n",
      "The inequality \\(2x + 3y \\leq 12\\) can be rewritten as:\n",
      "\n",
      "\\[\n",
      "3y \\leq 12 - 2x \\implies y \\leq \\frac{12 - 2x}{3}\n",
      "\\]\n",
      "\n",
      "Since \\(x,y \\geq 0\\), the feasible region is the set of points \\((x,y)\\) in the first quadrant under or on the line \\(2x + 3y = 12\\).\n",
      "\n",
      "---\n",
      "\n",
      "### Step 3: Find the vertices of the feasible region\n",
      "\n",
      "The feasible region is a polygon bounded by:\n",
      "\n",
      "- \\(x = 0\\)\n",
      "- \\(y = 0\\)\n",
      "- \\(2x + 3y = 12\\)\n",
      "\n",
      "The vertices are where the constraints intersect:\n",
      "\n",
      "1. Intersection of \\(x=0\\) and \\(y=0\\): \\((0,0)\\)\n",
      "2. Intersection of \\(x=0\\) and \\(2x+3y=12\\):\n",
      "   \\[\n",
      "   2(0) + 3y = 12 \\implies y = 4\n",
      "   \\]\n",
      "   So \\((0,4)\\).\n",
      "3. Intersection of \\(y=0\\) and \\(2x+3y=12\\):\n",
      "   \\[\n",
      "   2x + 3(0) = 12 \\implies x = 6\n",
      "   \\]\n",
      "   So \\((6,0)\\).\n",
      "\n",
      "---\n",
      "\n",
      "### Step 4: Evaluate the objective function at each vertex\n",
      "\n",
      "Since \\(f(x,y) = 3x + 4y\\) is linear, the maximum over a convex polygonal feasible region occurs at one of the vertices.\n",
      "\n",
      "- At \\((0,0)\\):\n",
      "  \\[\n",
      "  f(0,0) = 3(0) + 4(0) = 0\n",
      "  \\]\n",
      "\n",
      "- At \\((0,4)\\):\n",
      "  \\[\n",
      "  f(0,4) = 3(0) + 4(4) = 16\n",
      "  \\]\n",
      "\n",
      "- At \\((6,0)\\):\n",
      "  \\[\n",
      "  f(6,0) = 3(6) + 4(0) = 18\n",
      "  \\]\n",
      "\n",
      "---\n",
      "\n",
      "### Step 5: Conclusion\n",
      "\n",
      "The maximum value of \\(f(x,y)\\) is **18** at the point \\((6,0)\\).\n",
      "\n",
      "---\n",
      "\n",
      "### Step 6: Verify optimality\n",
      "\n",
      "- The feasible region is convex.\n",
      "- The objective function is linear.\n",
      "- Linear programming theory states that the maximum (or minimum) of a linear function over a convex polygonal region occurs at a vertex.\n",
      "- Among the vertices, \\((6,0)\\) gives the highest value, so it is the optimal solution.\n",
      "\n",
      "---\n",
      "\n",
      "### **Final answer:**\n",
      "\n",
      "\\[\n",
      "\\boxed{\n",
      "\\begin{cases}\n",
      "\\text{Maximum } f = 18 \\\\\n",
      "\\text{at } (x,y) = (6,0)\n",
      "\\end{cases}\n",
      "}\n",
      "\\]\n",
      "\n",
      "---\n",
      "\n",
      "If you'd like, I can also provide a graphical illustration or solve this using the method of Lagrange multipliers or other methods.\n",
      "\u001b[1;31;32m\n",
      "\n",
      "This model was automatically selected: gpt-4.1-mini-2025-04-14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C3PZSn6FWkJ2QcBp4aXa0C1g2QSFZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Let's solve the optimization problem step-by-step:\\n\\n---\\n\\n**Problem:**\\n\\nMaximize \\\\( f(x,y) = 3x + 4y \\\\)\\n\\nsubject to the constraints:\\n\\n\\\\[\\n\\\\begin{cases}\\n2x + 3y \\\\leq 12 \\\\\\\\\\nx \\\\geq 0 \\\\\\\\\\ny \\\\geq 0\\n\\\\end{cases}\\n\\\\]\\n\\n---\\n\\n### Step 1: Understand the problem\\n\\nWe want to find values of \\\\(x\\\\) and \\\\(y\\\\) that maximize the linear function \\\\(f(x,y) = 3x + 4y\\\\), but these values must satisfy the constraints.\\n\\nThe constraints form a feasible region in the first quadrant (since \\\\(x,y \\\\geq 0\\\\)) bounded by the line \\\\(2x + 3y = 12\\\\).\\n\\n---\\n\\n### Step 2: Identify the feasible region\\n\\nThe inequality \\\\(2x + 3y \\\\leq 12\\\\) can be rewritten as:\\n\\n\\\\[\\n3y \\\\leq 12 - 2x \\\\implies y \\\\leq \\\\frac{12 - 2x}{3}\\n\\\\]\\n\\nSince \\\\(x,y \\\\geq 0\\\\), the feasible region is the set of points \\\\((x,y)\\\\) in the first quadrant under or on the line \\\\(2x + 3y = 12\\\\).\\n\\n---\\n\\n### Step 3: Find the vertices of the feasible region\\n\\nThe feasible region is a polygon bounded by:\\n\\n- \\\\(x = 0\\\\)\\n- \\\\(y = 0\\\\)\\n- \\\\(2x + 3y = 12\\\\)\\n\\nThe vertices are where the constraints intersect:\\n\\n1. Intersection of \\\\(x=0\\\\) and \\\\(y=0\\\\): \\\\((0,0)\\\\)\\n2. Intersection of \\\\(x=0\\\\) and \\\\(2x+3y=12\\\\):\\n   \\\\[\\n   2(0) + 3y = 12 \\\\implies y = 4\\n   \\\\]\\n   So \\\\((0,4)\\\\).\\n3. Intersection of \\\\(y=0\\\\) and \\\\(2x+3y=12\\\\):\\n   \\\\[\\n   2x + 3(0) = 12 \\\\implies x = 6\\n   \\\\]\\n   So \\\\((6,0)\\\\).\\n\\n---\\n\\n### Step 4: Evaluate the objective function at each vertex\\n\\nSince \\\\(f(x,y) = 3x + 4y\\\\) is linear, the maximum over a convex polygonal feasible region occurs at one of the vertices.\\n\\n- At \\\\((0,0)\\\\):\\n  \\\\[\\n  f(0,0) = 3(0) + 4(0) = 0\\n  \\\\]\\n\\n- At \\\\((0,4)\\\\):\\n  \\\\[\\n  f(0,4) = 3(0) + 4(4) = 16\\n  \\\\]\\n\\n- At \\\\((6,0)\\\\):\\n  \\\\[\\n  f(6,0) = 3(6) + 4(0) = 18\\n  \\\\]\\n\\n---\\n\\n### Step 5: Conclusion\\n\\nThe maximum value of \\\\(f(x,y)\\\\) is **18** at the point \\\\((6,0)\\\\).\\n\\n---\\n\\n### Step 6: Verify optimality\\n\\n- The feasible region is convex.\\n- The objective function is linear.\\n- Linear programming theory states that the maximum (or minimum) of a linear function over a convex polygonal region occurs at a vertex.\\n- Among the vertices, \\\\((6,0)\\\\) gives the highest value, so it is the optimal solution.\\n\\n---\\n\\n### **Final answer:**\\n\\n\\\\[\\n\\\\boxed{\\n\\\\begin{cases}\\n\\\\text{Maximum } f = 18 \\\\\\\\\\n\\\\text{at } (x,y) = (6,0)\\n\\\\end{cases}\\n}\\n\\\\]\\n\\n---\\n\\nIf you'd like, I can also provide a graphical illustration or solve this using the method of Lagrange multipliers or other methods.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1754929314, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier=None, system_fingerprint='fp_4f3d32ad4e', usage=CompletionUsage(completion_tokens=828, prompt_tokens=69, total_tokens=897, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question for gpt-5 reasoning models\n",
    "prompt = \"\"\"\n",
    "You are solving an optimization problem: maximize f(x,y)=3x+4y subject to 2x+3y ≤ 12, x,y≥0. Show step-by-step reasoning, derive the solution, and explain why it’s optimal.\n",
    "\"\"\"\n",
    "modelrouter(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "327c58b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31;34m\n",
      "# Leveraging Federated Learning for Hospital Data Across Regulatory Jurisdictions: Privacy, Architecture, and Implementation\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "Hospitals generate vast amounts of sensitive patient data critical for improving clinical outcomes, advancing medical research, and optimizing healthcare delivery. However, sharing this data across institutions, especially those located in different regulatory jurisdictions, poses significant privacy, legal, and technical challenges. Federated Learning (FL), a decentralized machine learning paradigm, offers a promising approach to collaboratively train models on distributed hospital data without exposing raw patient information. This white paper explores how FL can be effectively applied to hospital data spanning multiple regulatory environments, addressing privacy challenges, proposing a secure and compliant architecture, and outlining a pragmatic three-step rollout plan.\n",
      "\n",
      "---\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Healthcare institutions worldwide strive to harness data-driven insights to improve patient care. However, strict regulations such as HIPAA in the United States, GDPR in the European Union, and other region-specific data protection laws often restrict data sharing across borders. Traditional centralized machine learning approaches require aggregating data in a central repository, creating risks of data breaches, non-compliance, and loss of patient trust.\n",
      "\n",
      "Federated Learning enables multiple hospitals to collaboratively develop machine learning models by training locally on their own data and sharing only model updates (e.g., gradients or weights) with a central aggregator. This approach maintains data privacy, reduces regulatory risk, and accelerates innovation. \n",
      "\n",
      "---\n",
      "\n",
      "## Privacy Challenges in Federated Learning for Hospital Data\n",
      "\n",
      "While FL preserves data locality, several privacy and security challenges remain, particularly in a multi-jurisdictional context:\n",
      "\n",
      "### 1. Regulatory Compliance\n",
      "\n",
      "- **Diverse Regulations:** Hospitals in different countries face varying regulations regarding data processing, storage, and transfer. Ensuring FL workflows comply with all applicable laws is complex.\n",
      "- **Data Sovereignty:** Some jurisdictions require that patient data never leaves national borders, which FL respects by design, but metadata and model updates may still be subject to scrutiny.\n",
      "\n",
      "### 2. Data Privacy Risks\n",
      "\n",
      "- **Inference Attacks:** Adversaries may attempt to reconstruct sensitive data from shared model updates via model inversion or membership inference attacks.\n",
      "- **Model Poisoning:** Malicious participants could inject corrupted updates to degrade model performance or introduce backdoors.\n",
      "\n",
      "### 3. Security Concerns\n",
      "\n",
      "- **Communication Security:** Model updates transmitted between hospitals and aggregators must be encrypted and authenticated to prevent interception or tampering.\n",
      "- **Participant Authentication:** Verifying the identity and trustworthiness of participating hospitals is essential to prevent unauthorized access.\n",
      "\n",
      "### 4. Technical Heterogeneity\n",
      "\n",
      "- **Data Distribution:** Non-IID (independent and identically distributed) data across hospitals can degrade FL model performance.\n",
      "- **System Capability Variation:** Differences in computational resources, network bandwidth, and IT infrastructure can affect participation and training efficiency.\n",
      "\n",
      "---\n",
      "\n",
      "## Proposed Federated Learning Architecture\n",
      "\n",
      "To address these challenges, the following architecture is proposed for a multi-jurisdictional FL system among hospitals:\n",
      "\n",
      "### 1. Federated Learning Participants\n",
      "\n",
      "- **Local Hospital Nodes:** Each hospital operates a local FL client responsible for:\n",
      "  - Preprocessing and securely storing patient data on-premises.\n",
      "  - Training local models using hospital data.\n",
      "  - Encrypting and sending model updates to the central aggregator.\n",
      "  - Enforcing local data governance policies compliant with jurisdictional laws.\n",
      "\n",
      "### 2. Central Aggregator Server\n",
      "\n",
      "- **Model Aggregation:** A trusted central server aggregates encrypted updates from all participants using secure aggregation protocols without accessing raw updates.\n",
      "- **Model Distribution:** The updated global model is redistributed to local nodes for subsequent training rounds.\n",
      "- **Compliance Monitoring:** Implements audit trails and access controls ensuring adherence to regulations.\n",
      "\n",
      "### 3. Privacy-Enhancing Technologies\n",
      "\n",
      "- **Secure Multi-Party Computation (SMPC):** Enables aggregation of model updates without revealing individual contributions.\n",
      "- **Differential Privacy:** Adds noise to model updates to prevent data leakage while maintaining model utility.\n",
      "- **Homomorphic Encryption:** Allows computation on encrypted data, further enhancing confidentiality during aggregation.\n",
      "\n",
      "### 4. Communication Layer\n",
      "\n",
      "- **Encrypted Channels:** Use of Transport Layer Security (TLS) for all communications.\n",
      "- **Authentication and Authorization:** Use of digital certificates or federated identity management to authenticate hospital nodes.\n",
      "\n",
      "### 5. Regulatory Compliance Layer\n",
      "\n",
      "- **Data Localization Policies:** Ensures no raw data or identifiable metadata leaves hospital premises.\n",
      "- **Legal Frameworks:** Incorporates data processing agreements and local legal counsel to align with jurisdictional requirements.\n",
      "\n",
      "---\n",
      "\n",
      "## Three-Step Rollout Plan\n",
      "\n",
      "A phased approach is recommended to ensure successful adoption, compliance, and technical robustness.\n",
      "\n",
      "### Step 1: Pilot Deployment and Feasibility Study\n",
      "\n",
      "- **Objective:** Validate the technical feasibility and regulatory compliance of FL within a controlled environment.\n",
      "- **Actions:**\n",
      "  - Select a small number of hospitals within one or two jurisdictions with compatible regulations.\n",
      "  - Develop a prototype FL system focusing on a specific use case (e.g., predicting patient readmission).\n",
      "  - Conduct privacy risk assessments and engage with legal teams to confirm compliance.\n",
      "  - Evaluate model performance, communication overhead, and participant feedback.\n",
      "- **Outcomes:**\n",
      "  - Proof of concept demonstrating privacy-preserving collaborative learning.\n",
      "  - Identification of technical or regulatory gaps requiring mitigation.\n",
      "\n",
      "### Step 2: Multi-Jurisdictional Expansion and Security Hardening\n",
      "\n",
      "- **Objective:** Expand the FL network to include hospitals across diverse regulatory jurisdictions.\n",
      "- **Actions:**\n",
      "  - Integrate privacy-enhancing technologies such as differential privacy and SMPC.\n",
      "  - Implement robust security measures including participant authentication and encrypted communication.\n",
      "  - Develop governance frameworks encompassing data use agreements, consent management, and audit mechanisms.\n",
      "  - Train hospital IT and data science teams on FL operations and compliance requirements.\n",
      "- **Outcomes:**\n",
      "  - A scalable, secure FL infrastructure compliant with multiple regulations.\n",
      "  - Enhanced trust among participating institutions.\n",
      "\n",
      "### Step 3: Full Production Rollout and Continuous Improvement\n",
      "\n",
      "- **Objective:** Operationalize FL across a broad network of hospitals with ongoing monitoring and optimization.\n",
      "- **Actions:**\n",
      "  - Deploy FL for multiple clinical use cases, such as diagnostic imaging or treatment outcome prediction.\n",
      "  - Establish continuous monitoring for model performance, privacy risks, and compliance adherence.\n",
      "  - Implement feedback loops to update policies, improve algorithms, and address emerging threats.\n",
      "  - Foster a collaborative community for knowledge sharing and innovation.\n",
      "- **Outcomes:**\n",
      "  - Sustained, privacy-compliant collaborative learning driving improved healthcare outcomes.\n",
      "  - A resilient FL ecosystem adaptable to evolving regulations and technologies.\n",
      "\n",
      "---\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Federated Learning presents a transformative opportunity for hospitals to collaboratively leverage their data assets while respecting stringent privacy and regulatory requirements across jurisdictions. By addressing privacy challenges through advanced cryptographic techniques, implementing a secure federated architecture, and adopting a thoughtful phased rollout plan, healthcare institutions can unlock the power of collective intelligence to advance patient care and medical research. This approach not only safeguards patient privacy but also fosters trust and innovation in an increasingly data-driven healthcare landscape.\n",
      "\n",
      "---\n",
      "\n",
      "## References\n",
      "\n",
      "- Kairouz, P., McMahan, H. B., et al. (2019). Advances and Open Problems in Federated Learning. *arXiv preprint arXiv:1912.04977*.\n",
      "- Rieke, N., Hancox, J., et al. (2020). The Future of Digital Health with Federated Learning. *npj Digital Medicine*, 3(1), 119.\n",
      "- European Medicines Agency. (2021). *Data Protection and Clinical Trials*.\n",
      "- U.S. Department of Health & Human Services. (2020). *HIPAA Privacy Rule and Sharing Information Related to Mental Health*.\n",
      "\n",
      "---\n",
      "\n",
      "*Prepared by: [Your Name]*  \n",
      "*Date: [Insert Date]*  \n",
      "*Contact: [Your Contact Information]*\n",
      "\u001b[1;31;32m\n",
      "\n",
      "This model was automatically selected: gpt-4.1-mini-2025-04-14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C3PZe6kUTIidLgvg12R22ybqj9ibm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# Leveraging Federated Learning for Hospital Data Across Regulatory Jurisdictions: Privacy, Architecture, and Implementation\\n\\n## Executive Summary\\n\\nHospitals generate vast amounts of sensitive patient data critical for improving clinical outcomes, advancing medical research, and optimizing healthcare delivery. However, sharing this data across institutions, especially those located in different regulatory jurisdictions, poses significant privacy, legal, and technical challenges. Federated Learning (FL), a decentralized machine learning paradigm, offers a promising approach to collaboratively train models on distributed hospital data without exposing raw patient information. This white paper explores how FL can be effectively applied to hospital data spanning multiple regulatory environments, addressing privacy challenges, proposing a secure and compliant architecture, and outlining a pragmatic three-step rollout plan.\\n\\n---\\n\\n## Introduction\\n\\nHealthcare institutions worldwide strive to harness data-driven insights to improve patient care. However, strict regulations such as HIPAA in the United States, GDPR in the European Union, and other region-specific data protection laws often restrict data sharing across borders. Traditional centralized machine learning approaches require aggregating data in a central repository, creating risks of data breaches, non-compliance, and loss of patient trust.\\n\\nFederated Learning enables multiple hospitals to collaboratively develop machine learning models by training locally on their own data and sharing only model updates (e.g., gradients or weights) with a central aggregator. This approach maintains data privacy, reduces regulatory risk, and accelerates innovation. \\n\\n---\\n\\n## Privacy Challenges in Federated Learning for Hospital Data\\n\\nWhile FL preserves data locality, several privacy and security challenges remain, particularly in a multi-jurisdictional context:\\n\\n### 1. Regulatory Compliance\\n\\n- **Diverse Regulations:** Hospitals in different countries face varying regulations regarding data processing, storage, and transfer. Ensuring FL workflows comply with all applicable laws is complex.\\n- **Data Sovereignty:** Some jurisdictions require that patient data never leaves national borders, which FL respects by design, but metadata and model updates may still be subject to scrutiny.\\n\\n### 2. Data Privacy Risks\\n\\n- **Inference Attacks:** Adversaries may attempt to reconstruct sensitive data from shared model updates via model inversion or membership inference attacks.\\n- **Model Poisoning:** Malicious participants could inject corrupted updates to degrade model performance or introduce backdoors.\\n\\n### 3. Security Concerns\\n\\n- **Communication Security:** Model updates transmitted between hospitals and aggregators must be encrypted and authenticated to prevent interception or tampering.\\n- **Participant Authentication:** Verifying the identity and trustworthiness of participating hospitals is essential to prevent unauthorized access.\\n\\n### 4. Technical Heterogeneity\\n\\n- **Data Distribution:** Non-IID (independent and identically distributed) data across hospitals can degrade FL model performance.\\n- **System Capability Variation:** Differences in computational resources, network bandwidth, and IT infrastructure can affect participation and training efficiency.\\n\\n---\\n\\n## Proposed Federated Learning Architecture\\n\\nTo address these challenges, the following architecture is proposed for a multi-jurisdictional FL system among hospitals:\\n\\n### 1. Federated Learning Participants\\n\\n- **Local Hospital Nodes:** Each hospital operates a local FL client responsible for:\\n  - Preprocessing and securely storing patient data on-premises.\\n  - Training local models using hospital data.\\n  - Encrypting and sending model updates to the central aggregator.\\n  - Enforcing local data governance policies compliant with jurisdictional laws.\\n\\n### 2. Central Aggregator Server\\n\\n- **Model Aggregation:** A trusted central server aggregates encrypted updates from all participants using secure aggregation protocols without accessing raw updates.\\n- **Model Distribution:** The updated global model is redistributed to local nodes for subsequent training rounds.\\n- **Compliance Monitoring:** Implements audit trails and access controls ensuring adherence to regulations.\\n\\n### 3. Privacy-Enhancing Technologies\\n\\n- **Secure Multi-Party Computation (SMPC):** Enables aggregation of model updates without revealing individual contributions.\\n- **Differential Privacy:** Adds noise to model updates to prevent data leakage while maintaining model utility.\\n- **Homomorphic Encryption:** Allows computation on encrypted data, further enhancing confidentiality during aggregation.\\n\\n### 4. Communication Layer\\n\\n- **Encrypted Channels:** Use of Transport Layer Security (TLS) for all communications.\\n- **Authentication and Authorization:** Use of digital certificates or federated identity management to authenticate hospital nodes.\\n\\n### 5. Regulatory Compliance Layer\\n\\n- **Data Localization Policies:** Ensures no raw data or identifiable metadata leaves hospital premises.\\n- **Legal Frameworks:** Incorporates data processing agreements and local legal counsel to align with jurisdictional requirements.\\n\\n---\\n\\n## Three-Step Rollout Plan\\n\\nA phased approach is recommended to ensure successful adoption, compliance, and technical robustness.\\n\\n### Step 1: Pilot Deployment and Feasibility Study\\n\\n- **Objective:** Validate the technical feasibility and regulatory compliance of FL within a controlled environment.\\n- **Actions:**\\n  - Select a small number of hospitals within one or two jurisdictions with compatible regulations.\\n  - Develop a prototype FL system focusing on a specific use case (e.g., predicting patient readmission).\\n  - Conduct privacy risk assessments and engage with legal teams to confirm compliance.\\n  - Evaluate model performance, communication overhead, and participant feedback.\\n- **Outcomes:**\\n  - Proof of concept demonstrating privacy-preserving collaborative learning.\\n  - Identification of technical or regulatory gaps requiring mitigation.\\n\\n### Step 2: Multi-Jurisdictional Expansion and Security Hardening\\n\\n- **Objective:** Expand the FL network to include hospitals across diverse regulatory jurisdictions.\\n- **Actions:**\\n  - Integrate privacy-enhancing technologies such as differential privacy and SMPC.\\n  - Implement robust security measures including participant authentication and encrypted communication.\\n  - Develop governance frameworks encompassing data use agreements, consent management, and audit mechanisms.\\n  - Train hospital IT and data science teams on FL operations and compliance requirements.\\n- **Outcomes:**\\n  - A scalable, secure FL infrastructure compliant with multiple regulations.\\n  - Enhanced trust among participating institutions.\\n\\n### Step 3: Full Production Rollout and Continuous Improvement\\n\\n- **Objective:** Operationalize FL across a broad network of hospitals with ongoing monitoring and optimization.\\n- **Actions:**\\n  - Deploy FL for multiple clinical use cases, such as diagnostic imaging or treatment outcome prediction.\\n  - Establish continuous monitoring for model performance, privacy risks, and compliance adherence.\\n  - Implement feedback loops to update policies, improve algorithms, and address emerging threats.\\n  - Foster a collaborative community for knowledge sharing and innovation.\\n- **Outcomes:**\\n  - Sustained, privacy-compliant collaborative learning driving improved healthcare outcomes.\\n  - A resilient FL ecosystem adaptable to evolving regulations and technologies.\\n\\n---\\n\\n## Conclusion\\n\\nFederated Learning presents a transformative opportunity for hospitals to collaboratively leverage their data assets while respecting stringent privacy and regulatory requirements across jurisdictions. By addressing privacy challenges through advanced cryptographic techniques, implementing a secure federated architecture, and adopting a thoughtful phased rollout plan, healthcare institutions can unlock the power of collective intelligence to advance patient care and medical research. This approach not only safeguards patient privacy but also fosters trust and innovation in an increasingly data-driven healthcare landscape.\\n\\n---\\n\\n## References\\n\\n- Kairouz, P., McMahan, H. B., et al. (2019). Advances and Open Problems in Federated Learning. *arXiv preprint arXiv:1912.04977*.\\n- Rieke, N., Hancox, J., et al. (2020). The Future of Digital Health with Federated Learning. *npj Digital Medicine*, 3(1), 119.\\n- European Medicines Agency. (2021). *Data Protection and Clinical Trials*.\\n- U.S. Department of Health & Human Services. (2020). *HIPAA Privacy Rule and Sharing Information Related to Mental Health*.\\n\\n---\\n\\n*Prepared by: [Your Name]*  \\n*Date: [Insert Date]*  \\n*Contact: [Your Contact Information]*', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1754929326, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier=None, system_fingerprint='fp_4f3d32ad4e', usage=CompletionUsage(completion_tokens=1571, prompt_tokens=59, total_tokens=1630, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question for GPT-4.1 series models\n",
    "prompt = \"\"\"\n",
    "Draft a 900–1200 word white paper explaining how federated learning can be applied to hospital data across different regulatory jurisdictions. Include privacy challenges, a proposed architecture, and a three-step rollout plan.\n",
    "\"\"\"\n",
    "modelrouter(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d4304c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31;34m\n",
      "Below are suggested test prompts you can send through the Azure OpenAI model router so you reliably trigger selection of each option (GPT-4.1 series, o4-mini, gpt-5 reasoning, gpt-5-chat). For each prompt I include the reason the router should prefer that model and one or two variants to increase the chance you’ll hit every model in the router’s decision logic.\n",
      "\n",
      "1) Target: gpt-5 reasoning (high-complexity, deep multi-step reasoning)\n",
      "- Prompt: “You are a logic tutor. Step-by-step, solve this puzzle and show your reasoning: A and B each pick a number 1–100. A says ‘my number is prime.’ B says ‘my number is a multiple of 3.’ After two further truthful yes/no statements by both, they can deduce each other’s numbers. Find one possible pair and explain each deduction step.”\n",
      "- Why: gpt-5 reasoning is optimized for extended, rigorous chain-of-thought-style reasoning and complex multi-step problems.\n",
      "- Variants: Hard math proof request, long causal chain in debugging a complex algorithm, or multi-step planning with constraints.\n",
      "\n",
      "2) Target: gpt-5-chat (conversational, sustained multi-turn chat)\n",
      "- Prompt: “Act as my product coach. Over a 10-message interactive conversation, help me refine a SaaS onboarding flow for an analytics tool: ask clarifying questions and adapt recommendations in each turn. Start by asking me three clarifying questions.”\n",
      "- Why: gpt-5-chat is tuned for multi-turn conversational contexts and role-based chat behaviors.\n",
      "- Variants: Ask for progressive iteration (design a user story, revise, polish), or ask to maintain persona across turns and refer back to earlier user replies.\n",
      "\n",
      "3) Target: GPT-4.1 series (generalist with creative + high-quality output)\n",
      "- Prompt: “Write a polished, 750-word article for a business audience explaining the benefits and risks of adopting generative AI in customer support. Include an executive summary, three actionable recommendations, and one short illustrative case study.”\n",
      "- Why: GPT-4.1 is usually chosen for high-quality prose, balanced creativity, and multi-paragraph structured outputs.\n",
      "- Variants: Creative writing (short story or marketing copy) or long-form technical explainers where quality and style matter.\n",
      "\n",
      "4) Target: o4-mini (fast, cost-efficient, lightweight tasks)\n",
      "- Prompt: “In one sentence, summarize this meeting transcript: [paste 2–4 short paragraphs]. Provide a three-bullet action list (each bullet ≤10 words).”\n",
      "- Why: o4-mini is selected for short, high-throughput, latency-sensitive, low-cost tasks like summarization or classification.\n",
      "- Variants: Quick classifications, short translations, label extraction, or concise Q/A.\n",
      "\n",
      "5) Additional coverage: force routing differences by emphasizing constraints the router might use\n",
      "- Low-latency preference (likely o4-mini): “Send me a 20-word summary only. I need it immediately.”\n",
      "- Safety/guardrails or system-instructions heavy (may choose GPT-4.1 or gpt-5-chat): “You are a safety reviewer: evaluate the following user-submitted instruction for potential policy violations and list which categories apply and why.”\n",
      "- Extremely large-context or multi-document synthesis (may prefer gpt-5 reasoning or GPT-4.1 depending on router weights): “Synthesize the following eight document snippets into a single research abstract (≤300 words). Highlight any contradictions.”\n",
      "\n",
      "Testing tips\n",
      "- Run each prompt multiple times and vary minor phrasing; routing can depend on context, metadata, latency settings, or system instructions.\n",
      "- If your router supports request metadata or “intent” fields, label requests (e.g., intent: “fast-summary”, “deep-reasoning”, “chat”) to help reproducibility.\n",
      "- To force multi-turn behavior for gpt-5-chat, actually conduct several exchanges rather than sending a single-shot prompt.\n",
      "- For o4-mini, keep outputs extremely short and mark “max_tokens” low and/or add “reply in <= 1 sentence” constraints.\n",
      "- For gpt-5 reasoning, include an explicit request for step-by-step chain-of-thought style reasoning (or ask for numbered logical steps) — that steers the router toward models specialized for that workload.\n",
      "\n",
      "If you want, I can convert these into ready-made API call payloads with example metadata fields to maximize the chance each query is routed to the intended model. Would you like that?\n",
      "\u001b[1;31;32m\n",
      "\n",
      "This model was automatically selected: gpt-5-mini-2025-08-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C3Pa3gR84nsWO1ywSGh1oShr7i8AM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Below are suggested test prompts you can send through the Azure OpenAI model router so you reliably trigger selection of each option (GPT-4.1 series, o4-mini, gpt-5 reasoning, gpt-5-chat). For each prompt I include the reason the router should prefer that model and one or two variants to increase the chance you’ll hit every model in the router’s decision logic.\\n\\n1) Target: gpt-5 reasoning (high-complexity, deep multi-step reasoning)\\n- Prompt: “You are a logic tutor. Step-by-step, solve this puzzle and show your reasoning: A and B each pick a number 1–100. A says ‘my number is prime.’ B says ‘my number is a multiple of 3.’ After two further truthful yes/no statements by both, they can deduce each other’s numbers. Find one possible pair and explain each deduction step.”\\n- Why: gpt-5 reasoning is optimized for extended, rigorous chain-of-thought-style reasoning and complex multi-step problems.\\n- Variants: Hard math proof request, long causal chain in debugging a complex algorithm, or multi-step planning with constraints.\\n\\n2) Target: gpt-5-chat (conversational, sustained multi-turn chat)\\n- Prompt: “Act as my product coach. Over a 10-message interactive conversation, help me refine a SaaS onboarding flow for an analytics tool: ask clarifying questions and adapt recommendations in each turn. Start by asking me three clarifying questions.”\\n- Why: gpt-5-chat is tuned for multi-turn conversational contexts and role-based chat behaviors.\\n- Variants: Ask for progressive iteration (design a user story, revise, polish), or ask to maintain persona across turns and refer back to earlier user replies.\\n\\n3) Target: GPT-4.1 series (generalist with creative + high-quality output)\\n- Prompt: “Write a polished, 750-word article for a business audience explaining the benefits and risks of adopting generative AI in customer support. Include an executive summary, three actionable recommendations, and one short illustrative case study.”\\n- Why: GPT-4.1 is usually chosen for high-quality prose, balanced creativity, and multi-paragraph structured outputs.\\n- Variants: Creative writing (short story or marketing copy) or long-form technical explainers where quality and style matter.\\n\\n4) Target: o4-mini (fast, cost-efficient, lightweight tasks)\\n- Prompt: “In one sentence, summarize this meeting transcript: [paste 2–4 short paragraphs]. Provide a three-bullet action list (each bullet ≤10 words).”\\n- Why: o4-mini is selected for short, high-throughput, latency-sensitive, low-cost tasks like summarization or classification.\\n- Variants: Quick classifications, short translations, label extraction, or concise Q/A.\\n\\n5) Additional coverage: force routing differences by emphasizing constraints the router might use\\n- Low-latency preference (likely o4-mini): “Send me a 20-word summary only. I need it immediately.”\\n- Safety/guardrails or system-instructions heavy (may choose GPT-4.1 or gpt-5-chat): “You are a safety reviewer: evaluate the following user-submitted instruction for potential policy violations and list which categories apply and why.”\\n- Extremely large-context or multi-document synthesis (may prefer gpt-5 reasoning or GPT-4.1 depending on router weights): “Synthesize the following eight document snippets into a single research abstract (≤300 words). Highlight any contradictions.”\\n\\nTesting tips\\n- Run each prompt multiple times and vary minor phrasing; routing can depend on context, metadata, latency settings, or system instructions.\\n- If your router supports request metadata or “intent” fields, label requests (e.g., intent: “fast-summary”, “deep-reasoning”, “chat”) to help reproducibility.\\n- To force multi-turn behavior for gpt-5-chat, actually conduct several exchanges rather than sending a single-shot prompt.\\n- For o4-mini, keep outputs extremely short and mark “max_tokens” low and/or add “reply in <= 1 sentence” constraints.\\n- For gpt-5 reasoning, include an explicit request for step-by-step chain-of-thought style reasoning (or ask for numbered logical steps) — that steers the router toward models specialized for that workload.\\n\\nIf you want, I can convert these into ready-made API call payloads with example metadata fields to maximize the chance each query is routed to the intended model. Would you like that?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1754929351, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1123, prompt_tokens=82, total_tokens=1205, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=192, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HARD question to test the model router\n",
    "prompt = \"\"\"\n",
    "The new model router model in azure openAI can route between these new models: \n",
    "GPT-4.1 series\n",
    "o4-mini\n",
    "gpt-5 reasoning models\n",
    "gpt-5-chat\n",
    "\n",
    "what questions do you suggest I ask so that I can see the model router selecting each and every model of the list?\n",
    "\"\"\"\n",
    "modelrouter(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
